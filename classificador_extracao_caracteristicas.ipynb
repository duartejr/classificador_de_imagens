{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modulo_03_projeto_04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NbPCoXvzVZUBHUvWUYIZ6i2RIoc1b4KU",
      "authorship_tag": "ABX9TyNtQYTYwAgo7Y4f+/Kf4KXj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duartejr/classificador_de_imagens/blob/main/classificador_extracao_caracteristicas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise de folhas de videira"
      ],
      "metadata": {
        "id": "L1SlCQlmbVet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grapevine Leaves Image Dataset - Kaggle\n"
      ],
      "metadata": {
        "id": "SjxadxbdbdC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercícios"
      ],
      "metadata": {
        "id": "Czngr9XAbkXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "sbRlA4kX0nsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Diretório onde estão armazenadas as imagens\n",
        "images_dir = '/content/drive/MyDrive/Blue_Edtech_Ciencia_Dados/Grapevine_Leaves_Image_Dataset'\n",
        "\n",
        "# Lista de sub diretórios \n",
        "sub_dirs = os.listdir(images_dir)"
      ],
      "metadata": {
        "id": "J0sVBJLyzoJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questão 1) Implemente uma rotina de carregamento das imagens \n"
      ],
      "metadata": {
        "id": "z5SqbU_YbpI_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJcvwT2hbSBC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def load_images(img_dir, folders):\n",
        "    '''\n",
        "    Rotina para carregamento das imagens:\n",
        "    Args:\n",
        "    img_dir (string) : Diretório onde as imagens estão armazenadas.\n",
        "    folder (list) : Lista com o nome dos subdiretórios onde as imagens estão armazenadas. \n",
        "\n",
        "    Returns:\n",
        "    X (np.array) : Array com as imagens carregadas\n",
        "    y (np.array) : Array com a categoria de cada uma das imagens\n",
        "    '''\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    for folder in folders:\n",
        "        images = glob(f'{img_dir}/{folder}/*.png')\n",
        "        for image_file in images:\n",
        "            image = Image.open(image_file)\n",
        "            X.append(image)\n",
        "            y.append(folder)\n",
        "\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questão 2) Faça a leitura das imagens e responda\n",
        "\n"
      ],
      "metadata": {
        "id": "KdcvlcWz1YRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leitura das imagens e das labels de cada uma delas."
      ],
      "metadata": {
        "id": "hZVrHvoFtVX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_images(images_dir, sub_dirs)"
      ],
      "metadata": {
        "id": "yoHkyWq11MwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f873034f-5ec3-471c-c194-2043faa4ae99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: FutureWarning: The input object of type 'PngImageFile' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'PngImageFile', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a) Qual a resolução das imagens deste dataset?"
      ],
      "metadata": {
        "id": "0UJBrKLRbsAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "width, height = X[0].size\n",
        "n_channels = len(X[0].getbands())\n",
        "mode = X[0].mode\n",
        "\n",
        "print(f'Resolução da imagem (Largura x Altura x Canais de cores) = {width}px x {height}px x {n_channels}')\n",
        "print(f'Modo de cores da imagem: {mode}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXs5iJzm1Xlu",
        "outputId": "5a8876a4-a675-494b-e9c8-7092fb7ca028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resolução da imagem (Largura x Altura x Canais de cores) = 511px x 511px x 4\n",
            "Modo de cores da imagem: RGBA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b) Quantas imagens por classe?"
      ],
      "metadata": {
        "id": "i7edysfG1gTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_categories(data):\n",
        "    unique, counts = np.unique(data, return_counts=True)\n",
        "\n",
        "    for category, count in zip(unique, counts):\n",
        "        print(f'Categoria: {category} | Nº de elementos: {count}')\n",
        "\n",
        "print_categories(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXLEsaPc2HtC",
        "outputId": "a17ba5bf-30c2-4c6d-88aa-53c82a9f4887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categoria: Ak | Nº de elementos: 100\n",
            "Categoria: Ala_Idris | Nº de elementos: 100\n",
            "Categoria: Buzgulu | Nº de elementos: 100\n",
            "Categoria: Dimnit | Nº de elementos: 100\n",
            "Categoria: Nazli | Nº de elementos: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### c) Este dataset já está estruturado em conjuntos treinamento/teste ou deve-se adotar alguma metodologia na modelagem?"
      ],
      "metadata": {
        "id": "F8oyKUDH2IOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O conjunto ainda não está dividio em conjuntos de treinamento e teste por isto será necessário implementar um método para realizar a separação deste dois grupos. A separação deve ser feita de forma que se garanta a proporcionalidade de classes existentes no grupo original. Um método que pode ser utilizado é o `train_test_split` do Scikit Learn. Para garantir a proporcionalidade das amostras pode-se utilizar o método `stratify` do `train_test_split`."
      ],
      "metadata": {
        "id": "ajN5_GWn3Rhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questão 3) Faça a preparação do dataset para extração de características com a CNN VGG-19. Qual o formato do input da rede? Verifique se há necessidade de transformação da imagem e, se sim, implemente esta transformação \n"
      ],
      "metadata": {
        "id": "Dy388TRG3Mye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O input da VGG-19 têm dimensão 224x224. As imagens do problema têm resolução 512x512 e 4 canais de cores. Será portanto necessário reduzir ajustar as dimensões das imagens para que seja possível utilizar a VGG-19."
      ],
      "metadata": {
        "id": "1HMD4zp053dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_images(images_list):\n",
        "    '''\n",
        "    Método para ajustar as imagens para as dimensões de entrada da VGG-19\n",
        "    Args:\n",
        "    images_list (np.Array) : Array de imagens a serem convertidas\n",
        "\n",
        "    Return:\n",
        "    images_converted (np.Array) : Array com as imagens ajustadas à configuração de entrada da VGG-19.\n",
        "    '''\n",
        "    images_converted = []\n",
        "\n",
        "    for image in images_list:\n",
        "        image = image.resize((224,224))     # Redimensiona imagem\n",
        "        image = image.convert('RGB')        # Converte de RGBA para RGB\n",
        "        image = np.asarray(image)           # Imagem para o formato np.Array\n",
        "        images_converted.append(image)\n",
        "    \n",
        "    return np.array(images_converted)\n"
      ],
      "metadata": {
        "id": "BLn8yIWe6L3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversão das imagens para o padrão de entrada da VGG-19."
      ],
      "metadata": {
        "id": "5ZGwKsWzujaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_converted = convert_images(X)"
      ],
      "metadata": {
        "id": "q1mNkZxZ-E6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questão 4) Implemente o processo de extração de características utilizando a VGG-19 e a transformação deste espaço de característica de forma adequada "
      ],
      "metadata": {
        "id": "qOC2cNGZ3oAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import vgg19\n",
        "\n",
        "def load_model():\n",
        "    '''\n",
        "    Método para carregar a VGG-19\n",
        "    '''\n",
        "    print(\"Carregando o modelo VGG19-ImageNet ...\")\n",
        "    model = vgg19.VGG19(include_top=True, weights='imagenet', input_shape=(224, 224, 3), classes=1000)\n",
        "    model = Model(inputs=model.input, outputs=model.get_layer(index=-2).output)\n",
        "    return model\n",
        "\n",
        "def predict(images, model):\n",
        "    '''\n",
        "    Método para realizar a seleção de características.\n",
        "    Args:\n",
        "    images (np.Array) : Array com o dado das imagens\n",
        "    model : Modelo que será utilizado para a seleção de características\n",
        "\n",
        "    Return:\n",
        "    np.Array : Array com os valores das características das imagens.\n",
        "    '''\n",
        "    prediction = np.array(model.predict(images))\n",
        "    return np.reshape(prediction , ((prediction.shape[0], sum(prediction.shape[1:]))))"
      ],
      "metadata": {
        "id": "tASZM6GQ3NW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model()                        # Inicializando o modelo\n",
        "X_features = predict(X_converted, model)    # Seleção das características\n",
        "print('Shape das features identificadas: ', X_features.shape)"
      ],
      "metadata": {
        "id": "JuGoKUxx3oXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fe5d050-e181-487b-e242-8c534cfc2063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando o modelo VGG19-ImageNet ...\n",
            "Shape das features identificadas:  (500, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questão 5) Utilize o espaço de características:"
      ],
      "metadata": {
        "id": "z8Y_2fFo-yjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### a) Se o conjunto não estiver particionado, escolha uma técnica e justifique sua decisão. Implemente esta rotina."
      ],
      "metadata": {
        "id": "djMxXPqQC7gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para particionar os grupos de treino e teste utilizarei o `train_test_split`. O grupo de treino terá 70% das amostras e o de teste 30% que é uma das divisões mais comumente utilizadas. Para garantir a proporcionalidade das amostras utilizarei o argumento `stratify` do `train_test_split`. Ao passar uma lista de referência para este argumento os conjuntos de treino e teste serão separados manetendo-se a proporcionalidade original das classes. Ou seja, como nos dados originais cada uma das amostras têm a mesma quantidade de exemplos será garantido que nos conjuntos de treino e teste terei exemplos de cada uma das categorias na mesma proporcionalidade."
      ],
      "metadata": {
        "id": "wx9uwU3KrwA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_sets(X, y):\n",
        "    '''\n",
        "    Método para realizar a separação dos grupos de treino e teste\n",
        "    '''\n",
        "    return train_test_split(X, y, test_size=.3, random_state=101, stratify=y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_sets(X_features, y)\n",
        "print('Categorias no conjunto de treino:\\n')\n",
        "print_categories(y_train)\n",
        "print()\n",
        "print('='*80)\n",
        "print('\\nCategorias no conjunto de teste:\\n')\n",
        "print_categories(y_test)"
      ],
      "metadata": {
        "id": "3JCys2c2C6th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ee2e0f9-e832-4500-8c99-74127f322fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categorias no conjunto de treino:\n",
            "\n",
            "Categoria: Ak | Nº de elementos: 70\n",
            "Categoria: Ala_Idris | Nº de elementos: 70\n",
            "Categoria: Buzgulu | Nº de elementos: 70\n",
            "Categoria: Dimnit | Nº de elementos: 70\n",
            "Categoria: Nazli | Nº de elementos: 70\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Categorias no conjunto de teste:\n",
            "\n",
            "Categoria: Ak | Nº de elementos: 30\n",
            "Categoria: Ala_Idris | Nº de elementos: 30\n",
            "Categoria: Buzgulu | Nº de elementos: 30\n",
            "Categoria: Dimnit | Nº de elementos: 30\n",
            "Categoria: Nazli | Nº de elementos: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### b) Utilize os dados com os classificadores Árvores de Decisão e Naive-Bayes. Obtenha a acurácia dos modelos e avalie os resultados."
      ],
      "metadata": {
        "id": "ra6YJ9bVC-eV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classificação utilizando a árvore de Decisão"
      ],
      "metadata": {
        "id": "V0GlkBoIw4IG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "DTC = DecisionTreeClassifier()\n",
        "DTC.fit(X_train, y_train)\n",
        "\n",
        "y_predicit_DTC = DTC.predict(X_test)\n",
        "print(classification_report(y_test, y_predicit_DTC))"
      ],
      "metadata": {
        "id": "fEzKsIYuC_Hf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7cac6d4-2d58-487c-ab25-0b993e44a4d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Ak       0.61      0.57      0.59        30\n",
            "   Ala_Idris       0.33      0.50      0.39        30\n",
            "     Buzgulu       0.44      0.37      0.40        30\n",
            "      Dimnit       0.42      0.47      0.44        30\n",
            "       Nazli       0.72      0.43      0.54        30\n",
            "\n",
            "    accuracy                           0.47       150\n",
            "   macro avg       0.50      0.47      0.47       150\n",
            "weighted avg       0.50      0.47      0.47       150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classificação utilizando o Naive Bayes"
      ],
      "metadata": {
        "id": "AVSYxTGnw7r7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "GNB = GaussianNB()\n",
        "GNB.fit(X_train, y_train)\n",
        "y_predict_GNB = GNB.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_predict_GNB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyCWFhtdD09B",
        "outputId": "676398b8-70ca-4024-966a-dba0f8a7da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          Ak       0.79      0.37      0.50        30\n",
            "   Ala_Idris       0.38      0.40      0.39        30\n",
            "     Buzgulu       0.54      0.63      0.58        30\n",
            "      Dimnit       0.37      0.43      0.40        30\n",
            "       Nazli       0.65      0.73      0.69        30\n",
            "\n",
            "    accuracy                           0.51       150\n",
            "   macro avg       0.54      0.51      0.51       150\n",
            "weighted avg       0.54      0.51      0.51       150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O modelo de Naive Bayes teve uma acurácia melhor que o da Árvore de Decisão, 0,54 contra 0,50. Porém, em ambos os casos, este valor é ainda é baixo, seria interessante tentar modificar os hiperparâmetros destes modelos para tentar melhorar a acurácia dos mesmos. Observa-se que as classes Ak e Nazli são as de melhor capacidade de predição em ambos os modeloos. E as classes Ala_Idris e Dmnit as que os modelos têm maior dificuldade de identifcar.  "
      ],
      "metadata": {
        "id": "hrP0HXGpxIix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bcdie_CQwyd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}